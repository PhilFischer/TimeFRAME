---
title: "The TimeFRAME Package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{The TimeFRAME Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

> This notebook presents an overview of the basic functionality including simulation of a data sets and application of stationary as well as time series inference models contained in the TimeFRAME package.

```{r, include = FALSE}
library(TimeFRAME)
library(tibble)
library(dplyr)
library(tidyr)
library(ggplot2)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.height = 5,
  fig.align = "center",
  out.width = "100%",
  comment = "#>"
)

set.seed(1)
```



# Dataset Simulation

The example contained in this notebook will be simulated from some fixed time series values of source contributions and fractionation weights. A total of $N = 64$ points will be generated with a measurement noise of $\eta = 5$ and using equally spaced time points $t \in [0,2]$, whose scaling is important for the interpretation of correlation lengths. Actually, the parameter values used for this simulation are contained in the package as the data set `n2o_weights2` with the generated values stored in `n2o_test2`.

```{r}
# Time series parameters
N <- 64
eta <- 5
t <- seq(0, 2, length.out = N)
n2o_labels <- c(d15N = bquote(delta^15 * "N"), d15NSP = bquote(delta^15 * "N" ^ "SP"))

# Fix source contributions and fractionation weight
d.weights <- data.frame(t = t) %>%
  mutate(f1 = 0.5 + cos(4*t)/(1+t)) %>%
  mutate(f1 = exp(f1)/(1+exp(f1)), f2 = 1-f1) %>%
  mutate(r1 = 0.1 + 0.1 * t) %>%
  rename(Ni = f1, bD = f2, Red = r1)

d.weights %>%
  pivot_longer(-t, names_to = "source") %>%
  mutate(source = factor(source, levels = names(d.weights)[2:4])) %>%
  ggplot() +
  geom_line(aes(x = t, y = value, col = source), linewidth = 1) +
  ylim(0, 1) +
  facet_grid(source ~ .) +
  xlab("Source") + ylab("Source Contribution and Fractionation Weight") +
  labs(col = "Time", title = "Fixed Values for f and r") +
  theme_bw() +
  theme(legend.position = "none")
```


In order to work with isotopic measurements a FRAME model must be defined using the function `frame_model`. Sources are extracted from the `n2o_sources` data set contained in the package by selecting only 2 sources and 2 measurements. The column index `c(1,2,4,5)` selects the first two columns for source means and the columns 4 and 5 for source spreads, which is also used for the fractionation factor. Now the model is defined with nitrification and bacterial denitrification sources considered in addition to fractionation and containing data of $\delta^{15}\mathrm{N}$ and $\delta^{15}\mathrm{N}^{SP}$ measurements.

The expected measurement after mixing and fractionation at each point in time can be computed with the `param_map` function by specifying the FRAME model and ground truth parameters. Simulated data can be created with the `sample_measurements` function in the same way, but by additionally specifying the measurement noise $\eta$ to be used.

```{r}
# Create model class
sources <- n2o_sources[1:2,c(1,2,4,5)]  # only 2 sources with 2 measurements
frac <- n2o_frac[,c(1,2,4,5)]  # only 2 measurements
model <- frame_model(sources, frac = frac)

# Compute measurement means
d.mean <- param_map(model, d.weights[,-1]) %>% 
  as.data.frame() %>%
  add_column(t = d.weights$t, .before = 1)

# Simulate measurements
d.meas <- sample_measurements(model, d.weights[,-1], eta) %>% 
  as.data.frame() %>%
  add_column(t = d.weights$t, .before = 1)

autoplot(model, d.meas[,2:3])
```


Simulated data uses source means and fractionation factors sampled from the parameters specified in the FRAME model over all points in time. The deviation from the expected mean measurement time series is thus a shift introduced by uncertain values of the source means and fractionation factors as well as independent measurement noise.

```{r}
# Plot means and sampled measurements
d.mean %>%
  pivot_longer(c(d15N, d15NSP), names_to = "variable", values_to = "mean") %>%
  inner_join(d.meas %>%
               pivot_longer(c(d15N, d15NSP), names_to = "variable"),
             by = c("t", "variable")) %>%
  mutate(variable = factor(variable, labels = n2o_labels)) %>%
  ggplot() +
  geom_line(aes(x = t, y = mean)) +
  geom_point(aes(x = t, y = mean), shape = 1) +
  geom_point(aes(x = t, y = value), col = "steelblue") +
  geom_linerange(aes(x = t, ymin = value, ymax = mean), col = "steelblue", alpha = 0.6) +
  geom_smooth(aes(x = t, y = value), col = "steelblue", fill = "steelblue") +
  facet_grid(variable ~ ., scales = "free_y", labeller = label_parsed) +
  xlab("Time") + ylab("Isotopic Measurement") +
  theme_bw()
```



# Stationary Inference

Stationary inference ignores time series information and treats the data as independent and identically distributed repetitions of the same data generating process. Therefore only one single estimate for each source contribution and fractionation weight should be computed.

## Isotopic Mapping

The isotopic mapping technique involves estimating source contribution and fractionation weights based on linear systems of equations. It is implemented in the function `isotope_map`. The measurement data is stripped of the time column and averaged over time, since the function otherwise returns one value per row instead of an average.

```{r}
meas <- d.meas[,2:3]
isotope_map(model, colMeans(meas))
```


The Bayesian version of isotopic mapping is the Fractionation and Mixing Evaluation (FRAME) technique. It estimates uncertainty from the defined model parameters and can be used with the function `fit_stationary`. For determining uncertainty, it is additionally required to give an estimate of measurement uncertainty as input. Fitting the model should take only a few seconds.

```{r, warning = FALSE}
system.time(
  fit <- fit_stationary(model, meas, eta)
)
```

With the function `coef`  the estimated source contribution and fractionation weights can be extracted from the model fit. They correspond to the posterior means of the parameters.

```{r}
coef(fit)
```

The full data frame with posterior means (`mean`), estimation errors (`se_mean`), standard deviations (`sd`) and quantiles (`X%`) can be extracted using the function `as.data.frame`. The effective sample size (`n_eff`) gives an indication of how reliable the estimates are, with high numbers corresponding to better estimates. Generally, values above 1000 are enough and they can be increased by sampling more iterations in the fitting functions using the optional `iter` argument. The Gelman-Rubin statistic (`Rhat`) indicates issues with the model specification and should be around 1. Values above 1.1 indicate poor convergence.

```{r}
as.data.frame(fit)
```

The `autoplot` function returns a `ggplot2` object of the fitted model that can be used to visually check the estimated parameters and equally-tailed credible intervals.

```{r}
autoplot(fit)
```



# Time Series Inference

Time series inference involves solving the mixing and fractionation equation at each point in time, where advanced models can make assumptions about smoothness of changes and correlation. 

The isotopic mapping implementation is vectorized over time, which means that if the full data set of measurements is used, it will return an estimate for each row. These estimates are then joined with the column of time points and plotted using `ggplot2` in the following cell.

```{r}
isotope_map(model, meas) %>%
  as.data.frame() %>%
  add_column(t = t) %>%
  pivot_longer(-t, names_to = "variable", values_to = "pred") %>%
  ggplot() +
  geom_line(aes(x = t, y = pred, col = variable), linewidth = 1) +
  ylim(0, 1) +
  facet_grid(variable ~ .) +
  xlab("Time") + ylab("Source Contribution and Fractionation Weight") + 
  labs(col = "Source", title = "Isotope Mapping") +
  theme_bw() +
  theme(legend.position = "none")
```


## Independent FRAME Model

The FRAME model can be used in a non-stationary way by computing an estimate at each point in time using the function `fit_frame`. Since this model does not make use of time series information, it is optional to specify the argument `t` with the time points where measurements were taken. In this notebook, the number of chains is reduced to 1 for shorter execution times using the argument `chains=1`. However, it is recommended to run with at least `chains=4` for an accurate assessment of model convergence. If processors with multiple cores are available, `cores=4` can be specified as well to run all chains simultaneously such that the execution time is not affected.

```{r}
system.time(
  fit.frame <- fit_frame(model, meas, t = t, eta = eta, chains = 1)
)
```

The function `coef` now returns a data frame with columns specifying the variable and corresponding source as well as time points with posterior means.

```{r}
head(coef(fit.frame))
```

The function `as.data.frame` returns a data frame of estimates, standard deviations, quantiles and convergence statistics for each parameter and each point in time.

```{r}
head(as.data.frame(fit.frame))
```

Using `autoplot` the fit can be visually assessed for the posterior mean and 95\% equally-tailed credible interval.

```{r}
autoplot(fit.frame)
```



## Spline GLM Model

Estimates can be constrained to be smooth using the spline GLM model implemented in the function `fit_glm`. It takes additional parameters `M` for the number of degrees of freedom in the estimate of source contribution weights and `M.r` for fractionation. Higher degrees of freedom allow for more changes and thus less smooth functions. Again, only a single chain is run with `chains=1` to reduce the execution time of this notebook, but at least `chains=4` is recommended.

```{r}
system.time(
  fit.glm <- fit_glm(model, meas, t = t, eta = eta, M = 8, M.r = 4, chains = 1)
)
```

The same extraction methods can be used with `coef` giving posterior means and `as.data.frame` a full data frame of estimates, standard deviations and quantiles. Using `autoplot`, the fitted values can be visually analyzed for the posterior mean and the 95\% equally-tailed credible interval.

```{r}
autoplot(fit.glm)
```



## Gaussian Process Model

Gaussian processes integrate a notion of smoothness by specifying correlation lengths commonly denoted by $\rho$. The implementation is available with the function `fit_gp` where the argument `rho` can be used to set the correlation length assumed for measurements. Again, only a single chain is run with `chains=1` to reduce the execution time of this notebook, but at least `chains=4` is recommended.

```{r}
system.time(
  fit.gp <- fit_gp(model, meas, t = t, eta = eta, rho = 0.2, chains = 1)
)
```

The same extraction methods can be used with `coef` giving posterior means and `as.data.frame` a full data frame of estimates, standard deviations and quantiles. Using `autoplot`, the fitted values can be visually analyzed for the posterior mean and the 95\% equally-tailed credible interval.

```{r}
autoplot(fit.gp)
```



## Dirichlet-Gaussian Process Model

A Dirichlet-Gaussian process is a generalization of the Gaussian process that can be applied to source contributions and fractionation directly, which gives it superior estimation properties. Similarly to regular Gaussian process models, the correlation lengths must be specified, but different values are allowed for source contribution weights with the argument `rho` and for fractionation with the argument `rho.r`. Again, only a single chain is run with `chains=1` to reduce the execution time of this notebook, but at least `chains=4` is recommended.

```{r}
system.time(
  fit.dgp <- fit_dgp(model, meas, t = t, rho = 0.3, rho.r = 0.6, eta = eta, chains = 1)
)
```

The same extraction methods can be used with `coef` giving posterior means and `as.data.frame` a full data frame of estimates, standard deviations and quantiles. Using `autoplot`, the fitted values can be visually analyzed for the posterior mean and the 95\% equally-tailed credible interval.

```{r}
autoplot(fit.dgp)
```



## Hierarchical Dirichlet-Gaussian Process Model

Setting fixed values of correlation lengths for the Dirichlet-Gaussian process model is not always useful, since they are generally not known in advance. Hierarchical estimation with `estim.rho=TRUE` incorporates this uncertainty and does not treat correlation length values as fixed, although rough estimates should still be specified with the `rho` and `rho.r` arguments respectively. Again, only a single chain is run with `chains=1` to reduce the execution time of this notebook, but at least `chains=4` is recommended.

```{r}
system.time(
  fit.hdgp <- fit_dgp(model, meas, t = t, rho = 0.3, rho.r = 0.6, eta = eta, estim.rho = TRUE, chains = 1)
)
```

The same extraction methods can be used with `coef` giving posterior means and `as.data.frame` a full data frame of estimates, standard deviations and quantiles. Using `autoplot`, the fitted values can be visually analyzed for the posterior mean and the 95\% equally-tailed credible interval.

```{r}
autoplot(fit.hdgp)
```





